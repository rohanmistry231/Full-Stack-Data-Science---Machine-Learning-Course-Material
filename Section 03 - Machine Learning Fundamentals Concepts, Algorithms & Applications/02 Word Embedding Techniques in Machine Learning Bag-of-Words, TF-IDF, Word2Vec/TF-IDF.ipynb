{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:Anaconda3]","language":"python","name":"conda-env-Anaconda3-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"4. TF-IDF.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"lVqkNbtWF4Kw"},"source":["# TF(Term Frequency)"]},{"cell_type":"markdown","metadata":{"id":"Znf7QSiEF4Kz"},"source":["- It is defined for a word w<sub>i</sub> in a **document d<sub>i</sub>**.\n","- It is defined as:\n","\n","> $$\\text{TF}(w_i, d_i) = \\frac{\\text{Number of occurrences of the word } w_i}{\\text{Total number of words in the document } d_i}$$"]},{"cell_type":"markdown","metadata":{"id":"s9LdT8R6F4K1"},"source":["- Term frequency of a word w<sub>i</sub> in a document d<sub>i</sub> lies between 0 and 1, i.e \n","> 0 <= TF(w<sub>i</sub>, d<sub>i</sub>) <= 1"]},{"cell_type":"markdown","metadata":{"id":"W2T88WdeF4K2"},"source":["- Since TF(w<sub>i</sub>, d<sub>i</sub>) lies between 0 and 1, it can be thought of as the probability of the word w<sub>i</sub> in document d<sub>i</sub>."]},{"cell_type":"markdown","metadata":{"id":"yMY059y8F4K3"},"source":["# IDF(Inverse Document Frequency)"]},{"cell_type":"markdown","metadata":{"id":"mpBS3eizF4K5"},"source":["- It is defined for a word w<sub>i</sub> in the **document corpus D<sub>c</sub>**.\n","- It is defined as:\n","\n","> $$\\text{IDF}(w_i, D_c) = \\log{\\frac{N}{n_i}}$$\n","<center>where N = Total number of documents</center>\n","\n","<center>$n_{i}$ = Number of documents in which the word w<sub>i</sub> occurs</center>"]},{"cell_type":"markdown","metadata":{"id":"uK-ye9kgF4K6"},"source":["- Since $n_{i}$ <= N (always), this implies $\\frac{N}{n_{i}}$ >= 1 (always). Hence, \n","> $$\\text{IDF}(w_i, D_c) = \\log{\\frac{N}{n_i} >= 0 \\text{ (Always)}}$$"]},{"cell_type":"markdown","metadata":{"id":"dG2QpkxAF4K8"},"source":["- From the above relations we can see that **if $n_{i}$ increases, IDF decreases and vice-versa**.\n","- That means if the word $w_{i}$ is more frequent, IDF will be small and if the word $w_{i}$ is rare then IDF will be large."]},{"cell_type":"markdown","metadata":{"id":"CJtwk7ymF4K-"},"source":["# TF-IDF"]},{"cell_type":"markdown","metadata":{"id":"nnfhfFzPF4K_"},"source":["- In this scheme, the value of any dimension of the vector $v_{i}$, corresponding to a document $d_{i}$, is calculated as:\n","\n","> $$\\text{TF}(w_i, d_i)*\\text{IDF}(w_i, D_c)$$\n","\n","- Usage example: Let there be 6 dimensions in a vector $v_{i}$ and every dimension represents a unique word as depicted below:\n","\n","| w<sub>1</sub> |  w<sub>2</sub>  |  w<sub>3</sub>  | w<sub>4</sub>  | w<sub>5</sub>  |w<sub>6</sub>  |\n","| --- |--- | --- | --- |--- |--- |\n","|  |  |  |  |  |  |  |\n","\n","- Then the value of the dimension corresponding to, say w<sub>4</sub>, is calculated as:\n","\n","$$\\text{TF}(w_4, d_i)*\\text{IDF}(w_4, D_c)$$"]},{"cell_type":"markdown","metadata":{"id":"f68xPt0UF4LA"},"source":["- TF-IDF gives more **importance to rarer words** in the **document corpus** because of the presence of **IDF** in the formula.\n","- Also, tf-idf gives more **importance to frequent words** in a **document** because of the presence of **TF** in the formula.\n","- This scheme doesn't consider the semantic meaning of words. For example the words 'tasty' and 'delicious' will have different dimensions, though they are semantically same."]},{"cell_type":"code","metadata":{"id":"P71xo9U3xLbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650214405867,"user_tz":-330,"elapsed":354,"user":{"displayName":"Akhil Vydyula","userId":"12835033834937061766"}},"outputId":"d8ff7526-70d9-4bc7-81e8-02610fd06be7"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","corpus = [\n","    'This is the first document.',\n","    'This document is the second document.',\n","    'And this is the third one.',\n","    'Is this the first document?',\n","]\n","\n","vectorizer = TfidfVectorizer()\n","\n","X = vectorizer.fit_transform(corpus)\n","\n","vectorizer.get_feature_names_out()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n","       'this'], dtype=object)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["print(X.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boeM9PE1cpA_","executionInfo":{"status":"ok","timestamp":1650214480146,"user_tz":-330,"elapsed":606,"user":{"displayName":"Akhil Vydyula","userId":"12835033834937061766"}},"outputId":"03dc1788-cd49-4347-cde7-e87102410fc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n","  0.38408524 0.         0.38408524]\n"," [0.         0.6876236  0.         0.28108867 0.         0.53864762\n","  0.28108867 0.         0.28108867]\n"," [0.51184851 0.         0.         0.26710379 0.51184851 0.\n","  0.26710379 0.51184851 0.26710379]\n"," [0.         0.46979139 0.58028582 0.38408524 0.         0.\n","  0.38408524 0.         0.38408524]]\n"]}]},{"cell_type":"code","source":["df =pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names())\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230},"id":"4kvOjOsjctFb","executionInfo":{"status":"ok","timestamp":1650214520101,"user_tz":-330,"elapsed":526,"user":{"displayName":"Akhil Vydyula","userId":"12835033834937061766"}},"outputId":"c709e4db-6000-4f98-a3a5-eb0d71e5dbe7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["        and  document     first        is       one    second       the  \\\n","0  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n","1  0.000000  0.687624  0.000000  0.281089  0.000000  0.538648  0.281089   \n","2  0.511849  0.000000  0.000000  0.267104  0.511849  0.000000  0.267104   \n","3  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000  0.384085   \n","\n","      third      this  \n","0  0.000000  0.384085  \n","1  0.000000  0.281089  \n","2  0.511849  0.267104  \n","3  0.000000  0.384085  "],"text/html":["\n","  <div id=\"df-5f96dfe5-e645-4b69-9ac6-04d1b5cc8a8a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and</th>\n","      <th>document</th>\n","      <th>first</th>\n","      <th>is</th>\n","      <th>one</th>\n","      <th>second</th>\n","      <th>the</th>\n","      <th>third</th>\n","      <th>this</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.469791</td>\n","      <td>0.580286</td>\n","      <td>0.384085</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.384085</td>\n","      <td>0.000000</td>\n","      <td>0.384085</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.687624</td>\n","      <td>0.000000</td>\n","      <td>0.281089</td>\n","      <td>0.000000</td>\n","      <td>0.538648</td>\n","      <td>0.281089</td>\n","      <td>0.000000</td>\n","      <td>0.281089</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.511849</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.267104</td>\n","      <td>0.511849</td>\n","      <td>0.000000</td>\n","      <td>0.267104</td>\n","      <td>0.511849</td>\n","      <td>0.267104</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.469791</td>\n","      <td>0.580286</td>\n","      <td>0.384085</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.384085</td>\n","      <td>0.000000</td>\n","      <td>0.384085</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f96dfe5-e645-4b69-9ac6-04d1b5cc8a8a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5f96dfe5-e645-4b69-9ac6-04d1b5cc8a8a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5f96dfe5-e645-4b69-9ac6-04d1b5cc8a8a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]}]}